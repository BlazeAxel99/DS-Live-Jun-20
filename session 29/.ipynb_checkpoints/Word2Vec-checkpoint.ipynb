{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as  np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors, word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(\"./GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_mango = word_vectors['mango']\n",
    "v_banana = word_vectors['banana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000001]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([v_banana],[v_banana])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd_one_out(words):\n",
    "    all_words_vector  = [word_vectors[w] for w in words]\n",
    "    \n",
    "    avg_vector = np.mean(all_words_vector , axis=0)\n",
    "    \n",
    "    odd_one_out = None\n",
    "    min_similarity = 1.0\n",
    "    \n",
    "    for w in words:\n",
    "        sim = cosine_similarity([word_vectors[w]], [avg_vector])\n",
    "        if sim < min_similarity:\n",
    "            min_similarity = sim\n",
    "            odd_one_out = w\n",
    "            \n",
    "    return odd_one_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paris'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_one_out(input_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = [\"apple\",\"mango\",\"juice\",\"party\",\"orange\"] \n",
    "input_2 = [\"music\",\"dance\",\"sleep\",\"dancer\",\"food\"]        \n",
    "input_3  = [\"match\",\"player\",\"football\",\"cricket\",\"dancer\"]\n",
    "input_4 = [\"india\",\"paris\",\"russia\",\"france\",\"germany\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Test/Test.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df =  [list(i) for i in df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in all_df:\n",
    "    result.append(odd_one_out(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['snake',\n",
       " 'teacher',\n",
       " 'cat',\n",
       " 'pineapple',\n",
       " 'India',\n",
       " 'is',\n",
       " 'was',\n",
       " 'Australia',\n",
       " 'Money',\n",
       " 'think',\n",
       " 'ship',\n",
       " 'Rome',\n",
       " 'Pool',\n",
       " 'Egypt',\n",
       " 'mouse',\n",
       " 'helmet',\n",
       " 'Universe',\n",
       " 'Kill',\n",
       " 'Club',\n",
       " 'Sun']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'OddOne':result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word Analogy Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogy(a,b,c):\n",
    "    a,b,c = a.lower(), b.lower(), c.lower()\n",
    "    \n",
    "    wa, wb, wc = word_vectors[a], word_vectors[b],word_vectors[c]\n",
    "    \n",
    "    d= None\n",
    "    max_sim = -100\n",
    "    \n",
    "    for w in word_vectors.vocab.keys():\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "            \n",
    "        wd = word_vectors[w]\n",
    "        \n",
    "        sim = cosine_similarity([wa-wb],[wd-wc])\n",
    "        \n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            d = w\n",
    "            \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clown_prince'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_analogy(\"man\",\"woman\",\"king\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-b3f5f1d38941>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"man\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"king\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"woman\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mnegative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36minit_sims\u001b[1;34m(self, replace)\u001b[0m\n\u001b[0;32m   1352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vectors_norm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"precomputing L2-norms of word weight vectors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_l2_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrelative_cosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_l2_norm\u001b[1;34m(m, replace)\u001b[0m\n\u001b[0;32m   2370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2371\u001b[0m     \"\"\"\n\u001b[1;32m-> 2372\u001b[1;33m     \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2373\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2374\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     35\u001b[0m          initial=_NoValue):\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word_vectors.most_similar(positive=[\"woman\",\"king\"], negative=[\"man\"], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"bollywood.txt\",'r', encoding='utf8')\n",
    "file = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_token = nltk.sent_tokenize(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sent in sent_token:\n",
    "    words = nltk.word_tokenize(sent)\n",
    "    words = [w.lower() for w in words if len(w)>2 and w not in sw]\n",
    "    data.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['deepika', 'padukone', 'ranveer', 'singh', 'wedding', 'one', 'biggest', 'bollywood', 'events', 'happened', '2018'], ['the', 'deepika', 'ranveer', 'celebrations', 'hooked', 'phones', 'waiting', 'come', 'also', 'gave', 'enough', 'reason', 'believe', 'stylish', 'two', 'couple'], ['from', 'airport', 'looks', 'reception', 'parties', 'everything', 'entire', 'timeline', 'deepika', 'ranveer', 'wedding', 'style', 'file'], ['not', 'ambanis', 'deepika', 'ranveer', 'priyanka', 'nick'], ['man', 'proves', 'wedding', 'the', 'year', 'this', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['from', 'isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['but', 'nothing', 'beats', 'man', 'wedding', 'the', 'year', 'award', 'social', 'media'], ['priyanka', 'also', 'shared', 'video', 'featuring', 'nick', 'jonaswas', 'also', 'celebrating', 'the', 'family', 'first', 'celebrated', 'christmas', 'london', 'pictures', 'priyanka', 'chopra', 'nick', 'jonas', 'new', 'year', 'celebrations', 'outstanding'], ['priyanka', 'chopra', 'nick', 'shared', 'glimpses', 'celebration', 'verbier', 'switzerland'], ['priyanka', 'chopra', 'married', 'nick', 'jonas', 'december', 'three', 'wedding', 'receptions', 'one', 'new', 'delhi', 'two', 'mumbai'], ['this', 'year', 'year', 'big', 'fat', 'lavish', 'extravagant', 'weddings'], ['from', 'isha', 'ambani', 'anand', 'piramal', 'deepika', 'padukone', 'ranveer', 'singh', 'priyanka', 'chopra', 'nick', 'jonas', 'kapil', 'sharma', 'ginni', 'chatrath', '2018', 'saw', 'many', 'grand', 'weddings'], ['but', 'nothing', 'beats', 'man', 'wedding', 'the', 'year', 'award', 'social', 'media'], ['kapil', 'sharma', 'ginni', 'chatrath', 'jaggo', 'night', 'december', 'made', 'even', 'special', 'industry', 'friends'], ['kapil', 'sharma', 'ginni', 'chatrath', 'friends', 'long', 'time'], ['there', 'virat', 'side', 'actress', 'wife', 'anushka', 'sharma', 'pleasure', 'audience'], ['while', 'couple', 'rang', 'new', 'year', 'style', 'morning', 'saw', 'virat', 'dress', 'squad', 'attire', 'anushka', 'pink', 'salwar', 'suit'], ['isha', 'ambani', 'married', 'anand', 'piramal', 'year']]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohit Uniyal\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(data,size=300,window=10, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=116, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "words  = list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deepika',\n",
       " 'padukone',\n",
       " 'ranveer',\n",
       " 'singh',\n",
       " 'wedding',\n",
       " 'one',\n",
       " 'biggest',\n",
       " 'bollywood',\n",
       " 'events',\n",
       " 'happened',\n",
       " '2018',\n",
       " 'the',\n",
       " 'celebrations',\n",
       " 'hooked',\n",
       " 'phones',\n",
       " 'waiting',\n",
       " 'come',\n",
       " 'also',\n",
       " 'gave',\n",
       " 'enough',\n",
       " 'reason',\n",
       " 'believe',\n",
       " 'stylish',\n",
       " 'two',\n",
       " 'couple',\n",
       " 'from',\n",
       " 'airport',\n",
       " 'looks',\n",
       " 'reception',\n",
       " 'parties',\n",
       " 'everything',\n",
       " 'entire',\n",
       " 'timeline',\n",
       " 'style',\n",
       " 'file',\n",
       " 'not',\n",
       " 'ambanis',\n",
       " 'priyanka',\n",
       " 'nick',\n",
       " 'man',\n",
       " 'proves',\n",
       " 'year',\n",
       " 'this',\n",
       " 'big',\n",
       " 'fat',\n",
       " 'lavish',\n",
       " 'extravagant',\n",
       " 'weddings',\n",
       " 'isha',\n",
       " 'ambani',\n",
       " 'anand',\n",
       " 'piramal',\n",
       " 'chopra',\n",
       " 'jonas',\n",
       " 'kapil',\n",
       " 'sharma',\n",
       " 'ginni',\n",
       " 'chatrath',\n",
       " 'saw',\n",
       " 'many',\n",
       " 'grand',\n",
       " 'but',\n",
       " 'nothing',\n",
       " 'beats',\n",
       " 'award',\n",
       " 'social',\n",
       " 'media',\n",
       " 'shared',\n",
       " 'video',\n",
       " 'featuring',\n",
       " 'jonaswas',\n",
       " 'celebrating',\n",
       " 'family',\n",
       " 'first',\n",
       " 'celebrated',\n",
       " 'christmas',\n",
       " 'london',\n",
       " 'pictures',\n",
       " 'new',\n",
       " 'outstanding',\n",
       " 'glimpses',\n",
       " 'celebration',\n",
       " 'verbier',\n",
       " 'switzerland',\n",
       " 'married',\n",
       " 'december',\n",
       " 'three',\n",
       " 'receptions',\n",
       " 'delhi',\n",
       " 'mumbai',\n",
       " 'jaggo',\n",
       " 'night',\n",
       " 'made',\n",
       " 'even',\n",
       " 'special',\n",
       " 'industry',\n",
       " 'friends',\n",
       " 'long',\n",
       " 'time',\n",
       " 'there',\n",
       " 'virat',\n",
       " 'side',\n",
       " 'actress',\n",
       " 'wife',\n",
       " 'anushka',\n",
       " 'pleasure',\n",
       " 'audience',\n",
       " 'while',\n",
       " 'rang',\n",
       " 'morning',\n",
       " 'dress',\n",
       " 'squad',\n",
       " 'attire',\n",
       " 'pink',\n",
       " 'salwar',\n",
       " 'suit']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.54790376e-04, -1.42996910e-03, -1.17495924e-03, -6.08305039e-04,\n",
       "       -2.79092463e-04,  1.81849464e-05,  1.08861644e-03, -1.11284910e-03,\n",
       "        1.19322131e-03,  6.43113861e-04, -1.56304298e-03, -1.51688379e-04,\n",
       "       -3.45179025e-04,  2.99815350e-04,  8.00156195e-05,  8.22971924e-04,\n",
       "        1.05872180e-03, -5.85068890e-04,  4.06241947e-04,  5.12084342e-04,\n",
       "       -4.88362566e-04, -1.47371262e-03,  6.28699840e-04,  1.48862507e-03,\n",
       "       -1.29115779e-03, -5.10995043e-04,  3.10722739e-04, -4.48817591e-04,\n",
       "       -7.41055526e-04, -8.98540544e-04, -1.10568269e-03,  1.45723356e-03,\n",
       "       -8.44730166e-05,  9.49555484e-04,  1.10128091e-03,  5.68656134e-04,\n",
       "       -7.61021744e-04, -5.39008994e-04, -1.54762238e-03, -1.65822252e-03,\n",
       "       -4.80267743e-04, -1.27190305e-03, -1.65298802e-03, -6.20207749e-04,\n",
       "       -1.47833163e-03,  3.08823728e-05,  1.07155414e-03,  6.24459062e-05,\n",
       "        1.19501527e-03,  1.87169877e-04,  1.00833317e-03,  2.16082262e-04,\n",
       "       -1.33038883e-03, -3.72473703e-04, -1.38426607e-03,  8.47085787e-04,\n",
       "        7.97935354e-05,  5.58748667e-04, -1.40135060e-03, -2.32530419e-05,\n",
       "        3.52516741e-04,  1.20900536e-03, -9.21233557e-04,  2.99899082e-04,\n",
       "        8.60448927e-04, -8.88403098e-04,  1.64644164e-03,  8.15874373e-04,\n",
       "        1.59705791e-03,  1.43198326e-04,  6.51040697e-04, -1.37944391e-03,\n",
       "        2.77420710e-04, -5.51833014e-04, -1.61311857e-03,  2.87193863e-04,\n",
       "        6.23605738e-04,  5.71406912e-04, -5.84279478e-04, -4.13034664e-04,\n",
       "       -1.00750453e-03,  3.25413712e-04, -7.67947291e-04, -1.61189854e-03,\n",
       "        5.64692833e-04, -1.65941706e-03,  1.00984180e-03,  1.26776856e-03,\n",
       "       -1.09155034e-03, -4.05822735e-04, -4.76452638e-04, -7.79213908e-04,\n",
       "       -1.66204432e-03, -1.52514072e-03, -4.04272083e-04, -8.55710881e-04,\n",
       "        1.28875149e-03,  3.04211222e-04,  4.01143450e-04,  1.24123646e-04,\n",
       "       -5.68075746e-04, -3.81400285e-04, -1.43285759e-03, -1.28952099e-03,\n",
       "        1.50161737e-03, -2.75703700e-04,  4.68218292e-04, -9.19204787e-04,\n",
       "       -1.51157100e-03, -8.93056917e-04,  3.88600194e-04, -7.93625368e-04,\n",
       "        1.40977150e-03,  1.61040132e-03,  1.25549594e-03,  4.97411122e-04,\n",
       "        1.18628005e-03, -9.32334980e-04,  7.18244875e-04, -1.40857021e-03,\n",
       "       -5.42171882e-04,  1.30269967e-03, -1.68843579e-03,  1.20544166e-03,\n",
       "       -1.23094360e-03,  1.11433852e-03, -8.60759057e-04,  1.50182983e-03,\n",
       "       -7.58623355e-05,  2.47986696e-04, -1.46773108e-03,  8.48886732e-04,\n",
       "        3.17717786e-04, -1.24005903e-03, -7.91133672e-04, -8.39536369e-04,\n",
       "        6.73496688e-04,  3.43634165e-04,  2.04538010e-04,  1.80455361e-04,\n",
       "        7.26305414e-04,  1.25584123e-03,  5.78026287e-04,  2.45669333e-04,\n",
       "        4.53640387e-04,  4.39511961e-04,  1.63599942e-03,  1.63927930e-03,\n",
       "        1.39046041e-03, -9.80231212e-04, -1.56680366e-03, -1.59307080e-03,\n",
       "       -9.32664843e-04, -7.90847815e-04,  1.16974225e-04, -1.26021495e-03,\n",
       "       -1.56133657e-03, -9.49084279e-05, -9.94364847e-04,  1.33052949e-04,\n",
       "        6.26616646e-04,  3.78573633e-04, -9.17305413e-04,  1.13986753e-05,\n",
       "       -6.11766533e-04, -6.63815008e-04, -1.41197955e-03, -1.20202219e-03,\n",
       "        1.11517310e-03, -7.35206238e-04, -1.55814807e-03, -1.41401519e-03,\n",
       "        8.11766949e-04, -1.24502985e-03, -1.57318835e-03, -1.27344707e-03,\n",
       "        1.45565812e-03,  8.32877355e-04,  5.75207116e-04, -1.37269788e-03,\n",
       "        2.97975115e-04, -3.28427210e-04,  5.70279139e-04, -1.10415032e-03,\n",
       "       -3.78253113e-04,  1.35719718e-03,  1.15308247e-03,  1.16216287e-03,\n",
       "       -2.44267023e-04, -8.38210050e-04,  7.42819917e-04,  4.57787188e-04,\n",
       "        6.30805094e-04, -1.65500294e-03, -1.18849811e-03,  2.15196909e-04,\n",
       "        7.61370175e-04,  1.22902123e-03, -3.50816583e-04, -1.80392904e-04,\n",
       "       -1.14643725e-03,  9.70669731e-04,  1.29506248e-03,  1.17568567e-03,\n",
       "        5.95438294e-04,  9.53748822e-04, -1.47149863e-03,  9.93170310e-04,\n",
       "       -7.17353192e-04, -8.38764827e-04, -7.12147739e-04, -1.00007607e-03,\n",
       "        4.84927703e-04, -1.30766199e-03, -1.51270139e-03,  4.11073532e-04,\n",
       "        1.59514404e-03,  2.27832264e-04, -1.45316613e-03,  3.26364592e-04,\n",
       "       -1.29603577e-04, -1.34936487e-03,  1.22138660e-03, -1.43572444e-03,\n",
       "        1.10929436e-03,  1.45158847e-03,  2.18752903e-04, -4.38877352e-04,\n",
       "        9.79086966e-04,  7.23278674e-04, -2.55535764e-04, -1.42720563e-03,\n",
       "       -1.21241307e-03, -1.16763241e-03,  1.03083474e-03,  2.41842674e-04,\n",
       "       -1.59987423e-03, -8.56255821e-04,  4.04077204e-04,  1.24783907e-03,\n",
       "       -1.41531695e-03, -4.51871019e-04,  1.01700006e-03,  7.25743826e-04,\n",
       "       -9.24340333e-04, -5.70623728e-04,  6.56017975e-04,  7.33352150e-04,\n",
       "        1.66829210e-03, -1.47522148e-03,  1.34155212e-03, -1.23599172e-03,\n",
       "       -1.13331189e-03, -1.58433267e-03, -1.54812448e-03,  2.02376657e-04,\n",
       "        1.39274064e-03,  3.54461023e-04,  4.23206257e-05,  4.50022519e-04,\n",
       "        1.64868485e-03,  1.17139099e-03,  2.49268691e-04,  1.17300998e-03,\n",
       "        3.29619710e-04, -1.09108584e-03,  1.45198230e-03, -1.01588143e-03,\n",
       "       -9.82005848e-04,  8.23917624e-04, -1.47635851e-03,  7.70978862e-04,\n",
       "       -1.59857247e-03, -1.07723742e-03,  1.17833482e-03,  3.84010404e-04,\n",
       "       -1.60600187e-03, -1.16787176e-03,  1.24899182e-03,  8.27859854e-04,\n",
       "       -1.40129169e-03, -5.49834745e-04,  7.40740870e-05, -5.14505897e-04,\n",
       "       -6.77930599e-04,  2.85547692e-04,  1.36401353e-03, -1.07008033e-03,\n",
       "        6.82596001e-04,  1.62586465e-03, -5.34771418e-04, -1.25292828e-03,\n",
       "       -1.32375886e-03, -1.00707391e-03,  1.50421995e-03,  3.10465577e-04,\n",
       "       -1.01809646e-03,  8.66994960e-04,  1.03592873e-04,  1.23154616e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['deepika']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"bollywood.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Word2Vec.load(\"bollywood.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_analogy(a,b,c, model):\n",
    "    a,b,c = a.lower(), b.lower(),c.lower()\n",
    "    wa,wb,wc = model[a],model[b],model[c]\n",
    "    \n",
    "    d = None\n",
    "    max_sim = -10\n",
    "    \n",
    "    actors = [\"ranveer\",\"deepika\",\"padukone\",\"singh\",\"nick\",\"jonas\",\"chopra\",\"priyanka\",\"virat\",\"anushka\",\"ginni\", \"sharma\"]\n",
    "    \n",
    "    for v in actors:\n",
    "        if v in [a,b,c]:\n",
    "            continue\n",
    "        sim = cosine_similarity([wb-wa],[model[v] - wc])\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            d = v\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'singh'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_analogy(\"deepika\",\"padukone\",\"anushka\",model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_actor(a,b,c,word_vectors):\n",
    "    \"\"\"Accepts a triad of words, a,b,c and returns d such that a is to b : c is to d\"\"\"\n",
    "    a,b,c = a.lower(),b.lower(),c.lower()\n",
    "    max_similarity = -100 \n",
    "    \n",
    "    d = None\n",
    "    words = actors\n",
    "    \n",
    "    wa,wb,wc = word_vectors[a],word_vectors[b],word_vectors[c]\n",
    "    \n",
    "    #to find d s.t similarity(|b-a|,|d-c|) should be max\n",
    "    \n",
    "    for w in words:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "        \n",
    "        wv = word_vectors[w]\n",
    "        sim = cosine_similarity([wb-wa],[wv-wc])\n",
    "        \n",
    "        if sim > max_similarity:\n",
    "            max_similarity = sim\n",
    "            d = w\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jonas'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triad = (\"deepika\",\"ranveer\",\"priyanka\")\n",
    "predict_actor(*triad,model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
